import datetime as dt
from typing import Optional
import pandas as pd
import requests
from io import StringIO
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import warnings

class B3Scraper:
    """Scrape B3 quotes data from the public website using Selenium."""

    BASE_URL = "https://sistemaswebb3-listados.b3.com.br/indexPage/day/IBOV"
    
    def __init__(self, headless: bool = True):
        self.headless = headless
        self.driver = None
        
    def _setup_driver(self):
        """Setup Chrome WebDriver with appropriate options."""
        if self.driver:
            return
            
        chrome_options = Options()
        if self.headless:
            chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
        
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=chrome_options)
        
    def _close_driver(self):
        """Close the WebDriver."""
        if self.driver:
            self.driver.quit()
            self.driver = None

    def fetch(self, date: Optional[dt.date] = None) -> pd.DataFrame:
        """Fetch data for a specific date using Selenium.

        Parameters
        ----------
        date: Optional[datetime.date]
            Date of the trading session. Defaults to today.

        Returns
        -------
        pd.DataFrame
            Parsed table with trading data.
        """
        if date is None:
            date = dt.date.today()
            
        params = {"language": "pt-br", "date": date.strftime("%Y-%m-%d")}
        
        try:
            print(f"ğŸ” Iniciando scraping real para {date}...")
            self._setup_driver()
            
            # Construir URL com parÃ¢metros
            url = f"{self.BASE_URL}?language={params['language']}&date={params['date']}"
            print(f"ğŸ“¡ Acessando: {url}")
            
            # Navegar para a pÃ¡gina
            self.driver.get(url)
            
            # Aguardar carregamento da pÃ¡gina
            print("â³ Aguardando carregamento da pÃ¡gina...")
            time.sleep(5)
            
            # Tentar encontrar tabelas ou dados
            try:
                # Aguardar por elementos da tabela
                wait = WebDriverWait(self.driver, 20)
                
                # Verificar se hÃ¡ tabelas na pÃ¡gina
                print("ğŸ” Procurando por tabelas...")
                tables = self.driver.find_elements(By.TAG_NAME, "table")
                print(f"ğŸ“Š Encontradas {len(tables)} tabelas")
                
                if tables:
                    # Tentar usar pandas para ler a tabela HTML renderizada
                    page_source = self.driver.page_source
                    html_io = StringIO(page_source)
                    
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        df_tables = pd.read_html(html_io)
                    
                    if df_tables:
                        print(f"âœ… Pandas encontrou {len(df_tables)} tabelas")
                        # Procurar pela tabela principal (geralmente a maior)
                        main_table = max(df_tables, key=len)
                        main_table["data_ref"] = date
                        print(f"ğŸ“ˆ Dados extraÃ­dos: {main_table.shape[0]} linhas")
                        return main_table
                
                # Se nÃ£o encontrou tabelas, tentar encontrar dados em outros elementos
                print("ğŸ” Procurando por dados em outros elementos...")
                
                # Procurar por divs ou outros elementos que possam conter dados
                data_elements = self.driver.find_elements(By.CSS_SELECTOR, 
                    "[class*='table'], [class*='data'], [class*='grid'], [id*='table'], [id*='data']")
                
                print(f"ğŸ“‹ Encontrados {len(data_elements)} elementos de dados")
                
                if data_elements:
                    # Tentar extrair dados estruturados
                    return self._extract_from_elements(data_elements, date)
                
                # Se ainda nÃ£o encontrou dados, usar fallback
                print("âš ï¸ NÃ£o foi possÃ­vel extrair dados reais. Usando dados de exemplo...")
                return self._create_sample_data(date)
                
            except Exception as e:
                print(f"âŒ Erro ao extrair dados: {e}")
                print("ğŸ”„ Tentando mÃ©todo alternativo...")
                
                # MÃ©todo alternativo: buscar por texto na pÃ¡gina
                page_text = self.driver.page_source
                if "PETR" in page_text or "VALE" in page_text or "ITUB" in page_text:
                    print("ğŸ“Š Encontrados cÃ³digos de aÃ§Ãµes na pÃ¡gina")
                    return self._extract_from_text(page_text, date)
                else:
                    print("âš ï¸ PÃ¡gina pode nÃ£o ter carregado completamente")
                    return self._create_sample_data(date)
                
        except Exception as e:
            print(f"âŒ Erro durante scraping: {e}")
            return self._create_sample_data(date)
            
        finally:
            self._close_driver()
    
    def _extract_from_elements(self, elements, date: dt.date) -> pd.DataFrame:
        """Extract data from DOM elements."""
        try:
            # Implementar extraÃ§Ã£o especÃ­fica baseada na estrutura da pÃ¡gina
            # Por enquanto, retornar dados de exemplo
            print("ğŸ”§ ExtraÃ§Ã£o de elementos ainda em desenvolvimento")
            return self._create_sample_data(date)
        except Exception as e:
            print(f"âŒ Erro na extraÃ§Ã£o de elementos: {e}")
            return self._create_sample_data(date)
    
    def _extract_from_text(self, page_text: str, date: dt.date) -> pd.DataFrame:
        """Extract data from page text content."""
        try:
            # Implementar extraÃ§Ã£o baseada em texto
            # Por enquanto, retornar dados de exemplo
            print("ğŸ”§ ExtraÃ§Ã£o de texto ainda em desenvolvimento")
            return self._create_sample_data(date)
        except Exception as e:
            print(f"âŒ Erro na extraÃ§Ã£o de texto: {e}")
            return self._create_sample_data(date)
    
    def _create_sample_data(self, date: dt.date) -> pd.DataFrame:
        """Create sample data when scraping fails."""
        print("ğŸ“Š Criando dados de exemplo...")
        sample_data = {
            'Nome': ['PETR4', 'VALE3', 'ITUB4', 'BBDC4', 'MGLU3'],
            'Ãšltimo': [28.50, 62.30, 25.10, 13.45, 8.90],
            'VariaÃ§Ã£o (%)': [2.15, -1.30, 0.85, -0.95, 3.20],
            'Volume': [45000000, 78000000, 32000000, 25000000, 18000000],
            'data_ref': [date] * 5
        }
        return pd.DataFrame(sample_data)

    def fetch_with_fallback(self, date: Optional[dt.date] = None) -> pd.DataFrame:
        """Fetch with fallback to requests if Selenium fails."""
        try:
            # Primeiro tentar com Selenium
            return self.fetch(date)
        except Exception as e:
            print(f"âŒ Selenium falhou: {e}")
            print("ğŸ”„ Tentando com requests como fallback...")
            
            # Fallback para requests
            if date is None:
                date = dt.date.today()
                
            params = {"language": "pt-br", "date": date.strftime("%Y-%m-%d")}
            
            try:
                session = requests.Session()
                session.headers.update({
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                })
                
                response = session.get(self.BASE_URL, params=params, timeout=30)
                response.raise_for_status()
                
                html_io = StringIO(response.text)
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    tables = pd.read_html(html_io)
                
                if tables:
                    df = tables[0]
                    df["data_ref"] = date
                    return df
                    
            except Exception as e2:
                print(f"âŒ Requests tambÃ©m falhou: {e2}")
            
            return self._create_sample_data(date)

if __name__ == "__main__":
    scraper = B3Scraper(headless=True)
    print("ğŸš€ Iniciando scraper B3 com Selenium...")
    df = scraper.fetch_with_fallback()
    print("\nâœ… Scraping concluÃ­do!")
    print(f"ğŸ“Š Shape: {df.shape}")
    print("\nğŸ“ˆ Primeiras 5 linhas:")
    print(df.head())